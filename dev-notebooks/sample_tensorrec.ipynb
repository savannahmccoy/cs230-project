{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SOURCE: https://github.com/jfkirk/tensorrec \n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import numpy\n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "import tensorrec\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Open and read in the ratings file\n",
    "# NOTE: This expects the ratings.csv file to be in the same folder as this Python file\n",
    "# You can download the MovieLens dataset, including ratings.csv, here:\n",
    "# https://grouplens.org/datasets/movielens/\n",
    "print('Loading ratings')\n",
    "with open('ratings.csv', 'r') as ratings_file:\n",
    "    ratings_file_reader = csv.reader(ratings_file)\n",
    "    raw_ratings = list(ratings_file_reader)\n",
    "    raw_ratings_header = raw_ratings.pop(0)\n",
    "\n",
    "# Iterate through the input to map MovieLens IDs to new internal IDs\n",
    "# The new internal IDs will be created by the defaultdict on insertion\n",
    "movielens_to_internal_user_ids = defaultdict(lambda: len(movielens_to_internal_user_ids))\n",
    "movielens_to_internal_item_ids = defaultdict(lambda: len(movielens_to_internal_item_ids))\n",
    "for row in raw_ratings:\n",
    "    row[0] = movielens_to_internal_user_ids[int(row[0])]\n",
    "    row[1] = movielens_to_internal_item_ids[int(row[1])]\n",
    "    row[2] = float(row[2])\n",
    "n_users = len(movielens_to_internal_user_ids)\n",
    "n_items = len(movielens_to_internal_item_ids)\n",
    "\n",
    "# Look at an example raw rating\n",
    "print(\"Raw ratings example:\\n{}\\n{}\".format(raw_ratings_header, raw_ratings[0]))\n",
    "\n",
    "# Shuffle the ratings and split them in to train/test sets 80%/20%\n",
    "random.shuffle(raw_ratings)  # Shuffles the list in-place\n",
    "cutoff = int(.8 * len(raw_ratings))\n",
    "train_ratings = raw_ratings[:cutoff]\n",
    "test_ratings = raw_ratings[cutoff:]\n",
    "print(\"{} train ratings, {} test ratings\".format(len(train_ratings), len(test_ratings)))\n",
    "\n",
    "\n",
    "# This method converts a list of (user, item, rating, time) to a sparse matrix\n",
    "def interactions_list_to_sparse_matrix(interactions):\n",
    "    users_column, items_column, ratings_column, _ = zip(*interactions)\n",
    "    return sparse.coo_matrix((ratings_column, (users_column, items_column)),\n",
    "                             shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "# Create sparse matrices of interaction data\n",
    "sparse_train_ratings = interactions_list_to_sparse_matrix(train_ratings)\n",
    "sparse_test_ratings = interactions_list_to_sparse_matrix(test_ratings)\n",
    "\n",
    "# Construct indicator features for users and items\n",
    "user_indicator_features = sparse.identity(n_users)\n",
    "item_indicator_features = sparse.identity(n_items)\n",
    "\n",
    "# Build a matrix factorization collaborative filter model\n",
    "cf_model = tensorrec.TensorRec(n_components=5)\n",
    "\n",
    "# Fit the collaborative filter model\n",
    "print(\"Training collaborative filter\")\n",
    "cf_model.fit(interactions=sparse_train_ratings,\n",
    "             user_features=user_indicator_features,\n",
    "             item_features=item_indicator_features)\n",
    "\n",
    "# Create sets of train/test interactions that are only ratings >= 4.0\n",
    "sparse_train_ratings_4plus = sparse_train_ratings.multiply(sparse_train_ratings >= 4.0)\n",
    "sparse_test_ratings_4plus = sparse_test_ratings.multiply(sparse_test_ratings >= 4.0)\n",
    "\n",
    "\n",
    "# This method consumes item ranks for each user and prints out recall@10 train/test metrics\n",
    "def check_results(ranks):\n",
    "    train_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_train_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    test_recall_at_10 = tensorrec.eval.recall_at_k(\n",
    "        test_interactions=sparse_test_ratings_4plus,\n",
    "        predicted_ranks=ranks,\n",
    "        k=10\n",
    "    ).mean()\n",
    "    print(\"Recall at 10: Train: {:.4f} Test: {:.4f}\".format(train_recall_at_10,\n",
    "                                                            test_recall_at_10))\n",
    "\n",
    "\n",
    "# Check the results of the MF CF model\n",
    "print(\"Matrix factorization collaborative filter:\")\n",
    "predicted_ranks = cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                        item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)\n",
    "\n",
    "# Let's try a new loss function: WMRB\n",
    "print(\"Training collaborative filter with WMRB loss\")\n",
    "ranking_cf_model = tensorrec.TensorRec(n_components=5,\n",
    "                                       loss_graph=tensorrec.loss_graphs.WMRBLossGraph())\n",
    "ranking_cf_model.fit(interactions=sparse_train_ratings_4plus,\n",
    "                     user_features=user_indicator_features,\n",
    "                     item_features=item_indicator_features,\n",
    "                     n_sampled_items=int(n_items * .01))\n",
    "\n",
    "# Check the results of the WMRB MF CF model\n",
    "print(\"WMRB matrix factorization collaborative filter:\")\n",
    "predicted_ranks = ranking_cf_model.predict_rank(user_features=user_indicator_features,\n",
    "                                                item_features=item_indicator_features)\n",
    "check_results(predicted_ranks)\n",
    "\n",
    "# To improve the recommendations, lets read in the movie genres\n",
    "print('Loading movie metadata')\n",
    "with open('movies.csv', 'r') as movies_file:\n",
    "    movies_file_reader = csv.reader(movies_file)\n",
    "    raw_movie_metadata = list(movies_file_reader)\n",
    "    raw_movie_metadata_header = raw_movie_metadata.pop(0)\n",
    "\n",
    "# Map the MovieLens IDs to our internal IDs and keep track of the genres and titles\n",
    "movie_genres_by_internal_id = {}\n",
    "movie_titles_by_internal_id = {}\n",
    "for row in raw_movie_metadata:\n",
    "    row[0] = movielens_to_internal_item_ids[int(row[0])]  # Map to IDs\n",
    "    row[2] = row[2].split('|')  # Split up the genres\n",
    "    movie_genres_by_internal_id[row[0]] = row[2]\n",
    "    movie_titles_by_internal_id[row[0]] = row[1]\n",
    "\n",
    "# Look at an example movie metadata row\n",
    "print(\"Raw metadata example:\\n{}\\n{}\".format(raw_movie_metadata_header,\n",
    "                                             raw_movie_metadata[0]))\n",
    "\n",
    "# Build a list of genres where the index is the internal movie ID and\n",
    "# the value is a list of [Genre, Genre, ...]\n",
    "movie_genres = [movie_genres_by_internal_id[internal_id]\n",
    "                for internal_id in range(n_items)]\n",
    "\n",
    "# Transform the genres into binarized labels using scikit's MultiLabelBinarizer\n",
    "movie_genre_features = MultiLabelBinarizer().fit_transform(movie_genres)\n",
    "n_genres = movie_genre_features.shape[1]\n",
    "print(\"Binarized genres example for movie {}:\\n{}\".format(movie_titles_by_internal_id[0],\n",
    "                                                          movie_genre_features[0]))\n",
    "\n",
    "# Coerce the movie genre features to a sparse matrix, which TensorRec expects\n",
    "movie_genre_features = sparse.coo_matrix(movie_genre_features)\n",
    "\n",
    "# Fit a content-based model using the genres as item features\n",
    "print(\"Training content-based recommender\")\n",
    "content_model = tensorrec.TensorRec(\n",
    "    n_components=n_genres,\n",
    "    item_repr_graph=tensorrec.representation_graphs.FeaturePassThroughRepresentationGraph(),\n",
    "    loss_graph=tensorrec.loss_graphs.WMRBLossGraph()\n",
    ")\n",
    "content_model.fit(interactions=sparse_train_ratings_4plus,\n",
    "                  user_features=user_indicator_features,\n",
    "                  item_features=movie_genre_features,\n",
    "                  n_sampled_items=int(n_items * .01))\n",
    "\n",
    "# Check the results of the content-based model\n",
    "print(\"Content-based recommender:\")\n",
    "predicted_ranks = content_model.predict_rank(user_features=user_indicator_features,\n",
    "                                             item_features=movie_genre_features)\n",
    "check_results(predicted_ranks)\n",
    "\n",
    "# Try concatenating the genres on to the indicator features for a hybrid recommender system\n",
    "full_item_features = sparse.hstack([item_indicator_features, movie_genre_features])\n",
    "\n",
    "print(\"Training hybrid recommender\")\n",
    "hybrid_model = tensorrec.TensorRec(\n",
    "    n_components=5,\n",
    "    loss_graph=tensorrec.loss_graphs.WMRBLossGraph()\n",
    ")\n",
    "hybrid_model.fit(interactions=sparse_train_ratings_4plus,\n",
    "                 user_features=user_indicator_features,\n",
    "                 item_features=full_item_features,\n",
    "                 n_sampled_items=int(n_items * .01))\n",
    "\n",
    "print(\"Hybrid recommender:\")\n",
    "predicted_ranks = hybrid_model.predict_rank(user_features=user_indicator_features,\n",
    "                                            item_features=full_item_features)\n",
    "check_results(predicted_ranks)\n",
    "\n",
    "# Print out movies that User #432 has liked\n",
    "print(\"User 432 liked:\")\n",
    "for m in sparse_train_ratings_4plus[432].indices:\n",
    "    print(movie_titles_by_internal_id[m])\n",
    "\n",
    "# Pull user 432's features out of the user features matrix and predict movie ranks for just that user\n",
    "u432_features = sparse.csr_matrix(user_indicator_features)[432]\n",
    "u432_rankings = hybrid_model.predict_rank(user_features=u432_features,\n",
    "                                          item_features=full_item_features)[0]\n",
    "\n",
    "# Get internal IDs of User 432's top 10 recommendations\n",
    "# These are sorted by item ID, not by rank\n",
    "# This may contain items with which User 432 has already interacted\n",
    "u432_top_ten_recs = numpy.where(u432_rankings <= 10)[0]\n",
    "print(\"User 432 recommendations:\")\n",
    "for m in u432_top_ten_recs:\n",
    "    print(movie_titles_by_internal_id[m])\n",
    "\n",
    "# Print out User 432's held-out interactions\n",
    "print(\"User 432's held-out movies:\")\n",
    "for m in sparse_test_ratings_4plus[432].indices:\n",
    "    print(movie_titles_by_internal_id[m])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
